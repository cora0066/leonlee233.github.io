<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Leon&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Leon&#39;s blog">
<meta property="og:url" content="https://leonlee233.github.io/index.html">
<meta property="og:site_name" content="Leon&#39;s blog">
<meta property="og:locale">
<meta property="article:author" content="Leon Lee">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@https:&#x2F;&#x2F;twitter.com&#x2F;leonwithleo">
  
    <link rel="alternate" href="/atom.xml" title="Leon's blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Leon&#39;s blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">主页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" target="_blank" rel="noopener" href="https://targaryenliu.com/">Gary</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://leonlee233.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Deformable-DETR中文翻译" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/11/06/Deformable-DETR%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91/" class="article-date">
  <time class="dt-published" datetime="2023-11-06T14:20:19.000Z" itemprop="datePublished">2023-11-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/11/06/Deformable-DETR%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91/">Deformable-DETR中文翻译</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="可变形自注意力机制是如何实现的"><a href="#可变形自注意力机制是如何实现的" class="headerlink" title="可变形自注意力机制是如何实现的"></a>可变形自注意力机制是如何实现的</h2><p>可变形自注意力机制从数学模型的角度来看，是通过修改标准Transformer模型中的自注意力计算来实现的。它改变了查询（Query）、键（Key）、值（Value）的计算方式，具体如下：</p>
<h3 id="标准自注意力（Self-Attention）"><a href="#标准自注意力（Self-Attention）" class="headerlink" title="标准自注意力（Self-Attention）"></a>标准自注意力（Self-Attention）</h3><ul>
<li>输入序列 ( X \in \mathbb{R}^{N \times C} )，其中 ( N ) 是序列长度，( C ) 是特征维度。</li>
<li>查询（Q）、键（K）和值（V）通过权重矩阵 ( W^Q, W^K, W^V ) 从 ( X ) 计算。</li>
<li>注意力权重通过 ( Q ) 和 ( K ) 的点积和softmax函数计算：<br>[<br>\text{Attention}(Q, K, V) &#x3D; \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V<br>]<br>其中 ( d_k ) 是键向量的维度。</li>
</ul>
<h3 id="可变形自注意力（Deformable-Self-Attention）"><a href="#可变形自注意力（Deformable-Self-Attention）" class="headerlink" title="可变形自注意力（Deformable Self-Attention）"></a>可变形自注意力（Deformable Self-Attention）</h3><ul>
<li>对于每个位置 ( i )，模型学习一组偏移量 ( \Delta p_{ij} ) 和注意力权重 ( A_{ij} )。</li>
<li>偏移量用于从 ( K ) 和 ( V ) 选择采样位置。</li>
<li>注意力权重 ( A_{ij} ) 通过变形点积和softmax函数计算：<br>[<br>\text{DeformableAttention}(Q, K, V) &#x3D; \sum_{j&#x3D;1}^{M} A_{ij}V(p_i + \Delta p_{ij})<br>]<br>( M ) 是每个位置的采样点数，( p_i ) 是原始位置。</li>
</ul>
<p>这种计算方式特别适用于图像任务，因为它在降低计算复杂度的同时，使模型能够专注于图像中最有信息量的部分。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2023/11/06/Deformable-DETR%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91/" data-id="clonvu4rs0005gwukcjbbh2xt" data-title="Deformable-DETR中文翻译" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-pytorch-加载数据集" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/11/02/pytorch-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/" class="article-date">
  <time class="dt-published" datetime="2023-11-02T00:51:49.000Z" itemprop="datePublished">2023-11-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/11/02/pytorch-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/">pytorch-加载数据集</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-写在前面"><a href="#1-写在前面" class="headerlink" title="1.写在前面"></a>1.写在前面</h2><p>由于自己在研究如何训练的时候走了很多弯路，因为从来没有体系化的学过python，甚至在学习如何加载数据集的时候就浪费了很多的时间</p>
<p>于是还是想系统化的把自己学到知识都总结一遍，方便自己遗忘时下次重新查看</p>
<h2 id="2-加载数据集的通常方法"><a href="#2-加载数据集的通常方法" class="headerlink" title="2.加载数据集的通常方法"></a>2.加载数据集的通常方法</h2><p>我们通常加载数据集的步骤是</p>
<p>1.定义数据集内的图片加载方式，裁切旋转等</p>
<p>2.定义Dataset，里有包括数据集的文件地址，数据集的一些增强功能，如果需要按照自己的要求来自定义数据集的处理方式，可以继承Dataset抽象类，实现__len__,_ <em>getitem</em>_,这两种方法即可</p>
<p>3.定义dataloader，他会把dataset转换为能让pytorch处理的数据类型，进行数据集的训练和验证</p>
<h2 id="Task-1：加载没有图片及Ccsv文件的文件夹分类的数据集"><a href="#Task-1：加载没有图片及Ccsv文件的文件夹分类的数据集" class="headerlink" title="Task 1：加载没有图片及Ccsv文件的文件夹分类的数据集"></a>Task 1：加载没有图片及Ccsv文件的文件夹分类的数据集</h2><p>当我们遇到一个数据集，里头的各类数据是用各个名称不同的文件夹组成的<br><img src="/download.png" alt="Alt text"><br>这个时候我们可以使用dataset里头的ImageFolder方法来创建Dataset<br>假定数据集文件在当前任务的&#x2F;data&#x2F;目录下，我们按照如下顺序来创建Dataset和dataloader</p>
<p>0.导包:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader,Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils,datasets</span><br></pre></td></tr></table></figure>


<p>1.定义数据加载方式:<br>这里的Transform是数据的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">32</span>), </span><br><span class="line">    transforms.CenterCrop(<span class="number">32</span>), </span><br><span class="line">    transforms.ToTensor(), </span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.492</span>, <span class="number">0.461</span>, <span class="number">0.417</span>],std=[<span class="number">0.256</span>, <span class="number">0.248</span>, <span class="number">0.251</span>]) </span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>2.创建dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_dataset = datasets.ImageFolder(root=<span class="string">&quot;/data/&quot;</span>,transform=data_transform)</span><br></pre></td></tr></table></figure>

<p>3.创建Dataloader:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_loader = DataLoader(my_dataset,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>) </span><br></pre></td></tr></table></figure>

<p>至此我们就得到了一个可以传入torch的进行计算的data_loader</p>
<h2 id="Task-2："><a href="#Task-2：" class="headerlink" title="Task 2："></a>Task 2：</h2><h2 id="Task-3："><a href="#Task-3：" class="headerlink" title="Task 3："></a>Task 3：</h2><h2 id="Task-4：我的数据集包含csv文件"><a href="#Task-4：我的数据集包含csv文件" class="headerlink" title="Task 4：我的数据集包含csv文件"></a>Task 4：我的数据集包含csv文件</h2><p>我们首先要清楚csv文件的列定义,例如我们这边有一个csv文件列的定义分类为    filename,label,我们对这个文件进行数据集加载</p>
<p><img src="/image.png" alt="Alt text"></p>
<p>0.导包:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils, datasets</span><br></pre></td></tr></table></figure>

<p>1.定义数据加载方式:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">224</span>), </span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>), </span><br><span class="line">    transforms.ToTensor(), </span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.492</span>, <span class="number">0.461</span>, <span class="number">0.417</span>], std=[<span class="number">0.256</span>, <span class="number">0.248</span>, <span class="number">0.251</span>]) </span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>2.创建dataset(<strong>通过继承Dataset类来自定义</strong>):</p>
<p>因为我们的数据不是通过文件夹分类的,所以我们需要使用pandas来解析csv</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, csv_file, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.data = pd.read_csv(csv_file)</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># 根据需要从csv中获取数据</span></span><br><span class="line">        sample = self.data.iloc[index]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 进行一些数据预处理操作</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sample</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line">```python</span><br></pre></td></tr></table></figure>

<p>3.创建Dataloader:</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2023/11/02/pytorch-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/" data-id="clonvu4rw000bgwukba2uhxbt" data-title="pytorch-加载数据集" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Code-Practice/" rel="tag">Code Practice</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-自注意力机制Self-attension笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/10/28/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6Self-attension%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2023-10-28T12:04:20.000Z" itemprop="datePublished">2023-10-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/10/28/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6Self-attension%E7%AC%94%E8%AE%B0/">自注意力机制Self-attension笔记</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="论文《Attention-is-All-You-Need》笔记目录"><a href="#论文《Attention-is-All-You-Need》笔记目录" class="headerlink" title="论文《Attention is All You Need》笔记目录"></a>论文《Attention is All You Need》笔记目录</h1><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><pre><code>这篇文章的摘要主要介绍了一下他们提出了一种简单的基于注意力机制开发的架构网络
</code></pre>
<ul>
<li>1.1 研究背景与动机</li>
<li>1.2 传统序列模型的局限性</li>
<li>1.3 Transformer模型的引入与意义</li>
</ul>
<h2 id="2-Transformer模型概述"><a href="#2-Transformer模型概述" class="headerlink" title="2. Transformer模型概述"></a>2. Transformer模型概述</h2><ul>
<li>2.1 注意力机制（Attention Mechanism）</li>
<li>2.2 多头自注意力机制（Multi-Head Self Attention）</li>
<li>2.3 前馈神经网络（Feedforward Neural Network）</li>
<li>2.4 残差连接与层归一化</li>
</ul>
<h2 id="3-模型架构详解"><a href="#3-模型架构详解" class="headerlink" title="3. 模型架构详解"></a>3. 模型架构详解</h2><ul>
<li>3.1 编码器（Encoder）架构</li>
<li>3.2 解码器（Decoder）架构</li>
<li>3.3 位置编码（Positional Encoding）</li>
</ul>
<h2 id="4-自注意力机制的数学原理"><a href="#4-自注意力机制的数学原理" class="headerlink" title="4. 自注意力机制的数学原理"></a>4. 自注意力机制的数学原理</h2><ul>
<li>4.1 Scaled Dot-Product Attention</li>
<li>4.2 多头自注意力的计算</li>
<li>4.3 注意力掩码（Attention Masking）</li>
</ul>
<h2 id="5-训练过程与优化"><a href="#5-训练过程与优化" class="headerlink" title="5. 训练过程与优化"></a>5. 训练过程与优化</h2><ul>
<li>5.1 损失函数</li>
<li>5.2 学习率调度</li>
<li>5.3 正则化与Dropout</li>
</ul>
<h2 id="6-实验与结果"><a href="#6-实验与结果" class="headerlink" title="6. 实验与结果"></a>6. 实验与结果</h2><ul>
<li>6.1 数据集与预处理</li>
<li>6.2 实验设置</li>
<li>6.3 评估指标与实验结果</li>
</ul>
<h2 id="7-与传统模型的对比研究"><a href="#7-与传统模型的对比研究" class="headerlink" title="7. 与传统模型的对比研究"></a>7. 与传统模型的对比研究</h2><ul>
<li>7.1 与循环神经网络（RNN）的对比</li>
<li>7.2 与卷积神经网络（CNN）的对比</li>
</ul>
<h2 id="8-应用与拓展"><a href="#8-应用与拓展" class="headerlink" title="8. 应用与拓展"></a>8. 应用与拓展</h2><ul>
<li>8.1 机器翻译任务</li>
<li>8.2 文本生成任务</li>
<li>8.3 图像处理等领域的拓展</li>
</ul>
<h2 id="9-总结与展望"><a href="#9-总结与展望" class="headerlink" title="9. 总结与展望"></a>9. 总结与展望</h2><ul>
<li>9.1 主要研究成果总结</li>
<li>9.2 可能的未来研究方向</li>
</ul>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li>A. 实现细节与代码解析</li>
<li>B. Transformer模型的变体与衍生</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2023/10/28/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6Self-attension%E7%AC%94%E8%AE%B0/" data-id="clonvu4s50011gwuk1pgqfess" data-title="自注意力机制Self-attension笔记" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Literature-Review/" rel="tag">Literature Review</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-卷积神经网络CNN笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2023-10-27T05:30:17.000Z" itemprop="datePublished">2023-10-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E7%AC%94%E8%AE%B0/">卷积神经网络CNN笔记</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-什么是卷积神经网络？"><a href="#1-什么是卷积神经网络？" class="headerlink" title="1. 什么是卷积神经网络？"></a>1. 什么是卷积神经网络？</h2><p>基本概念：卷积神经网络CNN（Convolutional Neural Networks）</p>
<p>是一种深度神经网络，最早在上世纪六十年代就已经被提出和研究了，最有名的使用卷积神经网络的两篇论文是</p>
<p>1998年的<strong>LeNet-5</strong>和2012年的<strong>AlexNet</strong></p>
        
          <p class="article-more-link">
            <a href="/2023/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E7%AC%94%E8%AE%B0/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2023/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E7%AC%94%E8%AE%B0/" data-id="clonvu4s0000lgwukcyi41uyw" data-title="卷积神经网络CNN笔记" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Literature-Review/" rel="tag">Literature Review</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-DETR笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/10/26/DETR%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2023-10-26T06:25:37.000Z" itemprop="datePublished">2023-10-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/10/26/DETR%E7%AC%94%E8%AE%B0/">文章总结：DETR笔记</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>DETR团队，提出了一种<strong>直接集合预测</strong>的新方法<br>因为之前的目标检测的工作都需要使用 例如:NMS(非极大抑制),Anchor(锚点)之类的管道来处理<br>这个地方如果简化管道的话,就能节省很多手工并且降低模型复杂度</p>
<p><img src="https://i.mji.rip/2023/10/26/d1ea8151a88087fcf70d315c1de23ecf.png" alt="DETR.png"></p>
        
          <p class="article-more-link">
            <a href="/2023/10/26/DETR%E7%AC%94%E8%AE%B0/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2023/10/26/DETR%E7%AC%94%E8%AE%B0/" data-id="clonvu4rt0006gwukfs09bfto" data-title="文章总结：DETR笔记" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Literature-Review/" rel="tag">Literature Review</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-一个好的开始" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/07/14/%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E5%BC%80%E5%A7%8B/" class="article-date">
  <time class="dt-published" datetime="2023-07-14T06:42:25.000Z" itemprop="datePublished">2023-07-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/07/14/%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E5%BC%80%E5%A7%8B/">一个好的开始</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="写在前头"><a href="#写在前头" class="headerlink" title="写在前头"></a>写在前头</h2><p>好久不见了各位，这里还是洋洋，我又一次回来了<br>沉寂了一年的博客又被我捡起来了<br>这过去的一年真的发生了好多事情啊</p>
        
          <p class="article-more-link">
            <a href="/2023/07/14/%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E5%BC%80%E5%A7%8B/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2023/07/14/%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E5%BC%80%E5%A7%8B/" data-id="clonvu4s2000sgwukcual197u" data-title="一个好的开始" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A5%87%E6%80%AA%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/" rel="tag">奇怪的碎碎念</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-linux系统的安装" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/11/20/linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85/" class="article-date">
  <time class="dt-published" datetime="2021-11-20T03:58:21.000Z" itemprop="datePublished">2021-11-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/11/20/linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85/">linux系统的安装</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>因为很多技术栈的技术都要求linux系统,安装linux系统得益于现在各大厂商对安装过程的简化,和图形化安装界面的优化已经做得非常好了,但是依旧有部分新手确实不太好入门,故写此文章记录自己的安装过程并且,提供一种安装教程供大家参考</p>
        
          <p class="article-more-link">
            <a href="/2021/11/20/linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2021/11/20/linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85/" data-id="clonvu4ry000fgwukbc4z733v" data-title="linux系统的安装" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-大数据基础step1-hadoop" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/11/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80step1-hadoop/" class="article-date">
  <time class="dt-published" datetime="2021-11-20T03:36:44.000Z" itemprop="datePublished">2021-11-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/11/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80step1-hadoop/">大数据基础step1:hadoop</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这个大三来的十分的匆忙 , 三个月转瞬即逝 , 这篇文章本来应该在两个月前就完成的 , 由于我的拖拖沓沓以及一些生活上的杂事 , 拖到现在才有时间把拖了两个多月的文章重新写出来 , 咳咳不废话了 , 接下来的这个系列是我这个学期学习的关于大数据课程的总结 , 希望能对看到这个的你有点帮助谢谢</p>
        
          <p class="article-more-link">
            <a href="/2021/11/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80step1-hadoop/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2021/11/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80step1-hadoop/" data-id="clonvu4s4000ygwukf3ty8ltl" data-title="大数据基础step1:hadoop" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Linux学习笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/06/05/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2021-06-05T07:27:50.000Z" itemprop="datePublished">2021-06-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/06/05/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Linux学习笔记</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一直想找个机会把学习的内容做个总结，下次忘记复习的时候就会舒服很多，遗憾的是直到最近我才把blog这个优秀的学习工具记起来，属实惭愧，路漫漫其修远兮</p>
        
          <p class="article-more-link">
            <a href="/2021/06/05/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2021/06/05/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" data-id="clonvu4rw000agwukfkw9ckjb" data-title="Linux学习笔记" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-好久不见" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/06/04/%E5%A5%BD%E4%B9%85%E4%B8%8D%E8%A7%81/" class="article-date">
  <time class="dt-published" datetime="2021-06-04T12:30:22.000Z" itemprop="datePublished">2021-06-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/06/04/%E5%A5%BD%E4%B9%85%E4%B8%8D%E8%A7%81/">好久不见</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="好久不见各位"><a href="#好久不见各位" class="headerlink" title="好久不见各位"></a>好久不见各位</h2><p>终于这个懒惰的小伙子终于找到了他博客的源文件，距离他上次博客更新约莫是在一年之前了，只记得当时还在因为C++和高等数学的期末考试而焦头烂额，一年过去之后的今天，他仍旧因为摸了一个学期的鱼而对期末考试充满了未知，但是不知道是因为长大之后的沉稳，还是摸鱼成性的躺平，他似乎并没有那么在意了，不知道这样的平常心面对的这一切是好是坏，至少他现在还是比较快乐的吧<br>
        
          <p class="article-more-link">
            <a href="/2021/06/04/%E5%A5%BD%E4%B9%85%E4%B8%8D%E8%A7%81/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2021/06/04/%E5%A5%BD%E4%B9%85%E4%B8%8D%E8%A7%81/" data-id="clonvu4s50010gwuk6rrzdnm8" data-title="好久不见" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%9E%E5%BF%86%E5%BD%95/" rel="tag">回忆录</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code-Practice/" rel="tag">Code Practice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hide/" rel="tag">Hide</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Literature-Review/" rel="tag">Literature Review</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E5%BF%86%E5%BD%95/" rel="tag">回忆录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A5%87%E6%80%AA%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/" rel="tag">奇怪的碎碎念</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97/" rel="tag">学习心得</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">学习笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%91%84%E5%BD%B1/" rel="tag">摄影</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%99%E7%A8%8B/" rel="tag">教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%B8%E8%AE%B0/" rel="tag">游记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BE%8E%E5%9B%BE/" rel="tag">美图</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Code-Practice/" style="font-size: 10px;">Code Practice</a> <a href="/tags/Hide/" style="font-size: 20px;">Hide</a> <a href="/tags/Literature-Review/" style="font-size: 14px;">Literature Review</a> <a href="/tags/%E5%9B%9E%E5%BF%86%E5%BD%95/" style="font-size: 12px;">回忆录</a> <a href="/tags/%E5%A5%87%E6%80%AA%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/" style="font-size: 10px;">奇怪的碎碎念</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97/" style="font-size: 18px;">学习心得</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">学习笔记</a> <a href="/tags/%E6%91%84%E5%BD%B1/" style="font-size: 14px;">摄影</a> <a href="/tags/%E6%95%99%E7%A8%8B/" style="font-size: 16px;">教程</a> <a href="/tags/%E6%B8%B8%E8%AE%B0/" style="font-size: 12px;">游记</a> <a href="/tags/%E7%BE%8E%E5%9B%BE/" style="font-size: 10px;">美图</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/11/06/Deformable-DETR%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91/">Deformable-DETR中文翻译</a>
          </li>
        
          <li>
            <a href="/2023/11/02/pytorch-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/">pytorch-加载数据集</a>
          </li>
        
          <li>
            <a href="/2023/10/28/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6Self-attension%E7%AC%94%E8%AE%B0/">自注意力机制Self-attension笔记</a>
          </li>
        
          <li>
            <a href="/2023/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E7%AC%94%E8%AE%B0/">卷积神经网络CNN笔记</a>
          </li>
        
          <li>
            <a href="/2023/10/26/DETR%E7%AC%94%E8%AE%B0/">文章总结：DETR笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Leon Lee<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">主页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a target="_blank" rel="noopener" href="https://targaryenliu.com/" class="mobile-nav-link">Gary</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>