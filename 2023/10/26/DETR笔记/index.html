<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>文章总结：DETR笔记 | Leon&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="1. 引言DETR团队，提出了一种直接集合预测的新方法因为之前的目标检测的工作都需要使用 例如:NMS(非极大抑制),Anchor(锚点)之类的管道来处理这个地方如果简化管道的话,就能节省很多手工并且降低模型复杂度">
<meta property="og:type" content="article">
<meta property="og:title" content="文章总结：DETR笔记">
<meta property="og:url" content="https://leonlee233.github.io/2023/10/26/DETR%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Leon&#39;s blog">
<meta property="og:description" content="1. 引言DETR团队，提出了一种直接集合预测的新方法因为之前的目标检测的工作都需要使用 例如:NMS(非极大抑制),Anchor(锚点)之类的管道来处理这个地方如果简化管道的话,就能节省很多手工并且降低模型复杂度">
<meta property="og:locale">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/d1ea8151a88087fcf70d315c1de23ecf.png">
<meta property="og:image" content="https://i.ytimg.com/an_webp/bSoZQkxc1Zw/mqdefault_6s.webp?du=3000&sqp=CJzj56kG&rs=AOn4CLDouVEkPcntV3L_AcEZJsYu0lyVlw">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/64e3c86958a7dc8f91fbd4134a3e7d8e.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/d1b0bc67acfd876f07634123f4af1a23.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/206e9ebdcae5b0056a217d7a00530711.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/a4bb123c87ec47b2446798c26a1cb78e.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/d58faa6fc3021fa3d5c20a2f96ff611f.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/5be91705f18fe6becc79b038b7a37270.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/b8fe475764ed70b70d3fd6ce14ad095e.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/62e342103a606084abdb6b7081ab3b9b.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/750512940e0159f31ab665cd5944f214.png">
<meta property="og:image" content="https://i.mji.rip/2023/10/26/4acd803fd1316e2a4a132b746e9c17b4.png">
<meta property="article:published_time" content="2023-10-26T06:25:37.000Z">
<meta property="article:modified_time" content="2023-10-26T14:21:24.500Z">
<meta property="article:author" content="Leon Lee">
<meta property="article:tag" content="Literature Review">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.mji.rip/2023/10/26/d1ea8151a88087fcf70d315c1de23ecf.png">
<meta name="twitter:creator" content="@https:&#x2F;&#x2F;twitter.com&#x2F;leonwithleo">
  
    <link rel="alternate" href="/atom.xml" title="Leon's blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Leon&#39;s blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">主页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" target="_blank" rel="noopener" href="https://targaryenliu.com/">Gary</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://leonlee233.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-DETR笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/10/26/DETR%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2023-10-26T06:25:37.000Z" itemprop="datePublished">2023-10-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      文章总结：DETR笔记
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>DETR团队，提出了一种<strong>直接集合预测</strong>的新方法<br>因为之前的目标检测的工作都需要使用 例如:NMS(非极大抑制),Anchor(锚点)之类的管道来处理<br>这个地方如果简化管道的话,就能节省很多手工并且降低模型复杂度</p>
<p><img src="https://i.mji.rip/2023/10/26/d1ea8151a88087fcf70d315c1de23ecf.png" alt="DETR.png"></p>
<span id="more"></span> 
<h2 id="2-主要贡献"><a href="#2-主要贡献" class="headerlink" title="2. 主要贡献"></a>2. 主要贡献</h2><p><strong>主要贡献上</strong></p>
<ul>
<li>他们提出了一种<strong>基于集合</strong>的<strong>全局损失函数</strong>,是通过二分匹配来进行强制的唯一匹配实现的，称作为<strong>集合预测</strong></li>
<li>他们没有像传统的工作那样采用循环神经网络(RNN)实现网络架构的neck部分,采用了能并行计算的<strong>Transformer</strong>的<strong>Encoder</strong>和<strong>Decoder</strong>架构</li>
</ul>
<p>以上是文章的两个核心的创新点</p>
<p><strong>在实验结果上</strong></p>
<ul>
<li>他们和2017年的Faster R-CNN进行了对比,发现性能结果相似,特别是在大的物体识别上性能表现良好</li>
<li>并且他们还测试了全景分割项目,表明这个架构能很容易的扩展到其他CV任务上</li>
</ul>
<p><strong>从现在的角度看</strong></p>
<ul>
<li>在当时DETR发布的时候确实性能表现并没有那么好，但是在如今我们去看PaperwithCode的官网上，在cocoval数据集上的目标检测任务上，前十名几乎全都是清一色的DETR的变体，确实也验证了作者所言不是吹嘘</li>
</ul>
<h2 id="3-DETR-方法详解"><a href="#3-DETR-方法详解" class="headerlink" title="3. DETR 方法详解"></a>3. DETR 方法详解</h2><h3 id="3-1-新的损失函数："><a href="#3-1-新的损失函数：" class="headerlink" title="3.1 新的损失函数："></a>3.1 新的损失函数：</h3><p>作者将这种新的损失函数称之为<strong>Object detection set prediction loss</strong></p>
<ul>
<li><p>什么是二分匹配</p>
<p>1.首先我们得知道什么是二分图，图的每一条边两端连接的两个顶点都分属两个集合，我们将这样的图称之为<strong>二分图</strong></p>
<p>有了二分图这个概念我们抛出一个问题，如果有三户人家的电视坏了，我们有三个电视维修工人分布在城市的不同位置，我们应给怎样安排维修，使得工人的路程<strong>开销最小</strong></p>
<p>对于这个问题我们就可以分析，工人和坏掉的电视之间就可以看作为二分图的两种不同顶点，如果不采用二分图的方式就可以使用穷举法，但是当问题的复杂度增加的情况下，穷举显然就不是一个很好的解决方案了</p>
<p>这个时候就涉及到图论中的<strong>二分图</strong>的<strong>最小和最大匹配</strong>的问题了<br>这个经典的问题我们可以使用<strong>匈牙利算法</strong>去实现<br><strong>youtube的匈牙利算法详解：</strong><br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=bSoZQkxc1Zw&t=742s"><img src="https://i.ytimg.com/an_webp/bSoZQkxc1Zw/mqdefault_6s.webp?du=3000&sqp=CJzj56kG&rs=AOn4CLDouVEkPcntV3L_AcEZJsYu0lyVlw" alt="youtube"></a></p>
</li>
<li><p>如何在目标检测中使用二分匹配<br>同样的，我们在这里也可以把训练集中的<strong>Ground Truth</strong>，和模型预测出来的<strong>Prediction</strong>分别看作为分属<strong>两个集合的顶点</strong>，这样我们就可以用已有的算法去解决问题<br><img src="https://i.mji.rip/2023/10/26/64e3c86958a7dc8f91fbd4134a3e7d8e.png" alt="64e3c86958a7dc8f91fbd4134a3e7d8e.png"><br>其中的yi就是Ground Truth，后面的y^i就是模型的预测值Prediction</p>
</li>
<li><p>完整损失函数<br>我们需要计算<em>类别损失</em>和<em>boundingbox的损失</em>也是就是下方表达式的左右两个部分<br><img src="https://i.mji.rip/2023/10/26/d1b0bc67acfd876f07634123f4af1a23.png" alt="d1b0bc67acfd876f07634123f4af1a23.png"><br>我们依次计算每一个，seq和GroundTruth的损失，就可以生成一个2维的tensor，通过匈牙利算法计算即可选出最小二分匹配</p>
</li>
</ul>
<h3 id="3-2-DETR模型中的Transformer"><a href="#3-2-DETR模型中的Transformer" class="headerlink" title="3.2 DETR模型中的Transformer"></a>3.2 DETR模型中的Transformer</h3><p>DETR模型中的Transformer是经过改良的变形金刚模型<br>具体模型对比可以看图<br><img src="https://i.mji.rip/2023/10/26/206e9ebdcae5b0056a217d7a00530711.png" alt="Transformer对比.png"></p>
<h4 id="3-2-0-Backbone-和-Spatial-Positional-Embedding"><a href="#3-2-0-Backbone-和-Spatial-Positional-Embedding" class="headerlink" title="3.2.0 Backbone 和 Spatial Positional Embedding"></a>3.2.0 Backbone 和 Spatial Positional Embedding</h4><p>前面忘记说DETR的前半部分模型了<br><img src="https://i.mji.rip/2023/10/26/a4bb123c87ec47b2446798c26a1cb78e.png" alt="DETR前半部分模型.png"></p>
<p>这里包含DETR的Backbone和一部分Encoder，我们一步一步来介绍</p>
<h5 id="Backbone"><a href="#Backbone" class="headerlink" title="Backbone"></a>Backbone</h5><p>首先我们可以看看上面的CNN和flatten，这里原版的卷积层采用了ResNet-50和101（删去了最后的平均池化和Linear）用于提取图像的特征信息</p>
<p>之后通过了一个1*1的conv_layer给FeatureMap降维，然后是Flatten操作将序列的维度改变</p>
<h5 id="Encoder前半部分"><a href="#Encoder前半部分" class="headerlink" title="Encoder前半部分"></a>Encoder前半部分</h5><p>这个地方是之前和标准Transformer不一样的地方，就是我们提到的<strong>Spatial positional embedding</strong><br>这个Spatial positional embedding会参与<br>1.<em>Encoder</em>中多头注意力<strong>Query</strong>和<strong>Key tensor</strong>的生成<br>2.<em>Decoder</em>中<strong>cross attention</strong>里头的Key的生成</p>
<p>这个Spatial positional embedding主要采用<strong>正弦函数</strong>生成<br>正弦函数的讲解可以看这个视频<br><img src="https://i.mji.rip/2023/10/26/d58faa6fc3021fa3d5c20a2f96ff611f.png" alt="正余弦编码.png"><br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=dichIcUZfOw&t=546s">https://www.youtube.com/watch?v=dichIcUZfOw&amp;t=546s</a></p>
<h4 id="3-2-1-Transformer编码器-Encoder"><a href="#3-2-1-Transformer编码器-Encoder" class="headerlink" title="3.2.1 Transformer编码器(Encoder)"></a>3.2.1 Transformer编码器(Encoder)</h4><p>每一个传入Encoder中的向量，都将穿过多层的自注意力和全连接层<br>去捕捉序列中的依赖关系和每个图像patch之间的关系</p>
<p><img src="https://i.mji.rip/2023/10/26/5be91705f18fe6becc79b038b7a37270.png" alt="5be91705f18fe6becc79b038b7a37270.png"></p>
<p>从图像中可以看出来，经过Encoder之后，选取几个物体身上的不同的像素点，他们能将这个物体的边缘和大体结构分辨的很好</p>
<h4 id="3-2-2-Transformer解码器-Decoder"><a href="#3-2-2-Transformer解码器-Decoder" class="headerlink" title="3.2.2 Transformer解码器(Decoder)"></a>3.2.2 Transformer解码器(Decoder)</h4><p>DETR中的<strong>Transformer Decoder</strong>中不仅仅接收<strong>Encoder</strong>中的输出，还接收一个特定的<strong>object_quierys</strong>，这是一个<strong>可以学习</strong>的tensor，在计算注意力的时候会不断的更新，学习图像之间的<strong>位置关系</strong>和<strong>类别信息</strong>，最后用于<strong>FFN</strong>的分类和<strong>BoundingBox</strong>置信度的计算</p>
<p><img src="https://i.mji.rip/2023/10/26/b8fe475764ed70b70d3fd6ce14ad095e.png" alt="b8fe475764ed70b70d3fd6ce14ad095e.png"></p>
<p>这是Decoder的输出结果可视化，可以看得出来在图像内物体识别任务上，Decoder可以很好地区别遮挡物体之间的层次关系<br><img src="https://i.mji.rip/2023/10/26/62e342103a606084abdb6b7081ab3b9b.png" alt="62e342103a606084abdb6b7081ab3b9b.png"><br>小象用橙色标记，大象用蓝色标记，我们可以发现在物体边缘处（鼻子，脚掌的位置），能够将两个物体区别的很开</p>
<h3 id="3-3-前向传播的检测头Feed-forward-Network-FFN"><a href="#3-3-前向传播的检测头Feed-forward-Network-FFN" class="headerlink" title="3.3 前向传播的检测头Feed-forward Network(FFN)"></a>3.3 前向传播的检测头Feed-forward Network(FFN)</h3><p>最后用两个不同的FFN得出分类的置信度和Boundingbox的置信度，这个地方就采用了集合预测损失函数</p>
<p><img src="https://i.mji.rip/2023/10/26/750512940e0159f31ab665cd5944f214.png" alt="750512940e0159f31ab665cd5944f214.png"></p>
<p>最终预测结果由一个具有 ReLU 激活函数和隐藏维度 d 的 3 层感知器和一个线性投影层计算得出。</p>
<p>FFN预测输入图像的标准化中心坐标、高度和宽度，线性层使用softmax函数预测类标签。</p>
<p>N个边界框，N通常远大于图像中感兴趣对象的实际数量，因此使用额外的特殊类标签∅来表示在某个位置内没有检测到对象。</p>
<h2 id="4-实验与结果"><a href="#4-实验与结果" class="headerlink" title="4. 实验与结果"></a>4. 实验与结果</h2><p><img src="https://i.mji.rip/2023/10/26/4acd803fd1316e2a4a132b746e9c17b4.png" alt="4acd803fd1316e2a4a132b746e9c17b4.png"></p>
<h4 id="评价标准的解读"><a href="#评价标准的解读" class="headerlink" title="评价标准的解读"></a>评价标准的解读</h4><p>GFLOPS（Giga Floating Point Operations Per Second）:它是衡量模型计算效率的指标，通常与硬件的计算能力相关联。<br>FPS（Frames Per Second）:FPS表示模型每秒处理的图像帧数。<br>params（Number of Parameters）:表示模型中的参数数量<br>AP（Average Precision）:用于评估模型的准确性。它是对模型在不同置信度阈值下的精度的平均值。<br>AP50: 它是当置信度阈值为50%时的精度。<br>AP75 它是当置信度阈值为75%时的精度。<br>APS（AP Small）, APM（AP Medium）, APL（AP Large）:分别用于评估小目标、中等目标和大目标的检测性能。</p>
<h4 id="总的来说"><a href="#总的来说" class="headerlink" title="总的来说"></a>总的来说</h4><p>最后采用了Faster-RCNN作为baseline，在coco val数据集上测试<br><strong>DETR</strong>模型实现了与经过大量调整的<strong>Faster R-CNN</strong>基线相当的结果，其APS较低，但APL有很大提高。<br>得出这个结果我们也不意外，因为<strong>Transformer的局部扑捉能力是不如CNN</strong>的，这导致了<strong>小物体的检测性能较差</strong><br>但是也是得益于Transformer的<strong>全局注意力</strong>，在<strong>大物体上</strong>的目标检测性能意外的不错</p>
<h2 id="5-优势与局限性"><a href="#5-优势与局限性" class="headerlink" title="5. 优势与局限性"></a>5. 优势与局限性</h2><ul>
<li>探讨DETR方法相对于传统目标检测方法的优势</li>
<li>分析DETR方法可能存在的局限性和改进方向</li>
</ul>
<h2 id="6-应用领域和前景展望"><a href="#6-应用领域和前景展望" class="headerlink" title="6. 应用领域和前景展望"></a>6. 应用领域和前景展望</h2><ul>
<li>探讨DETR在实际应用中的潜力和前景</li>
<li>提出可能的扩展和应用方向</li>
</ul>
<h2 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h2><ul>
<li>总结DETR的重要性和创新之处</li>
<li>强调DETR对目标检测领域的影响</li>
</ul>
<h2 id="8-参考文献"><a href="#8-参考文献" class="headerlink" title="8. 参考文献"></a>8. 参考文献</h2><ul>
<li>列举DETR论文以及其他相关参考文献</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://leonlee233.github.io/2023/10/26/DETR%E7%AC%94%E8%AE%B0/" data-id="clo89ilwf00020suk2cbrfng0" data-title="文章总结：DETR笔记" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Literature-Review/" rel="tag">Literature Review</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E7%AC%94%E8%AE%B0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Neuer</strong>
      <div class="article-nav-title">
        
          卷积神经网络CNN笔记
        
      </div>
    </a>
  
  
    <a href="/2023/07/14/%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E5%BC%80%E5%A7%8B/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">一个好的开始</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hide/" rel="tag">Hide</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Literature-Review/" rel="tag">Literature Review</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E5%BF%86%E5%BD%95/" rel="tag">回忆录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A5%87%E6%80%AA%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/" rel="tag">奇怪的碎碎念</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97/" rel="tag">学习心得</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">学习笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%91%84%E5%BD%B1/" rel="tag">摄影</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%99%E7%A8%8B/" rel="tag">教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%B8%E8%AE%B0/" rel="tag">游记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BE%8E%E5%9B%BE/" rel="tag">美图</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hide/" style="font-size: 20px;">Hide</a> <a href="/tags/Literature-Review/" style="font-size: 12px;">Literature Review</a> <a href="/tags/%E5%9B%9E%E5%BF%86%E5%BD%95/" style="font-size: 12px;">回忆录</a> <a href="/tags/%E5%A5%87%E6%80%AA%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/" style="font-size: 10px;">奇怪的碎碎念</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97/" style="font-size: 18px;">学习心得</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">学习笔记</a> <a href="/tags/%E6%91%84%E5%BD%B1/" style="font-size: 14px;">摄影</a> <a href="/tags/%E6%95%99%E7%A8%8B/" style="font-size: 16px;">教程</a> <a href="/tags/%E6%B8%B8%E8%AE%B0/" style="font-size: 12px;">游记</a> <a href="/tags/%E7%BE%8E%E5%9B%BE/" style="font-size: 10px;">美图</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E7%AC%94%E8%AE%B0/">卷积神经网络CNN笔记</a>
          </li>
        
          <li>
            <a href="/2023/10/26/DETR%E7%AC%94%E8%AE%B0/">文章总结：DETR笔记</a>
          </li>
        
          <li>
            <a href="/2023/07/14/%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E5%BC%80%E5%A7%8B/">一个好的开始</a>
          </li>
        
          <li>
            <a href="/2021/11/20/linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85/">linux系统的安装</a>
          </li>
        
          <li>
            <a href="/2021/11/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80step1-hadoop/">大数据基础step1:hadoop</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Leon Lee<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">主页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a target="_blank" rel="noopener" href="https://targaryenliu.com/" class="mobile-nav-link">Gary</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>